<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home - The ARKR Manual on The AI Engineer&#39;s Handbook</title>
    <link>https://ai.arkr.ca/index.html</link>
    <description>Recent content in Home - The ARKR Manual on The AI Engineer&#39;s Handbook</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://ai.arkr.ca/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Coding Tools</title>
      <link>https://ai.arkr.ca/ai-coding-tools.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/ai-coding-tools.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;What is vibe coding?&lt;/strong&gt; AI-assisted development for rapid prototyping and iteration. Trade-offs: speed vs. maintainability.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: &lt;strong&gt;Cursor&lt;/strong&gt; (AI IDE, Composer, agent mode, &lt;code&gt;.cursor/rules&lt;/code&gt;). &lt;strong&gt;Claude Code&lt;/strong&gt; (CLI, &lt;code&gt;/init&lt;/code&gt;, &lt;code&gt;/clear&lt;/code&gt;, &lt;code&gt;CLAUDE.md&lt;/code&gt;, thinking modes). &lt;strong&gt;GitHub Copilot&lt;/strong&gt; (autocomplete, chat). &lt;strong&gt;Others&lt;/strong&gt;: Windsurf, Aider, Cline. Comparing features and choosing the right tool.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI vs. ML vs. DL</title>
      <link>https://ai.arkr.ca/ai-vs-ml-vs-dl.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/ai-vs-ml-vs-dl.html</guid>
      <description>&lt;p&gt;Definitions and the hierarchy of intelligence. History of &amp;ldquo;Good Old Fashioned AI&amp;rdquo; (GOFAI) vs. connectionism. &lt;strong&gt;Key terminology&lt;/strong&gt;: tokens, context windows, model weights/parameters, AI vs. AGI. The three learning paradigms: supervised, unsupervised, and reinforcement learning (RLHF for LLMs).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Embeddings &amp; Vector Search</title>
      <link>https://ai.arkr.ca/embeddings-vector-search.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/embeddings-vector-search.html</guid>
      <description>&lt;p&gt;Understanding embeddings: turning text into high-dimensional vectors. Embedding models (OpenAI, Sentence Transformers). &lt;strong&gt;Vector databases&lt;/strong&gt;: Pinecone, Weaviate, Chroma, FAISS, pgvector, Qdrant. &lt;strong&gt;Vector search&lt;/strong&gt;: similarity metrics (cosine, dot product), indexing (HNSW, IVF), nearest-neighbor at scale. Use cases: semantic search, recommendations, anomaly detection.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Essentials</title>
      <link>https://ai.arkr.ca/python-essentials.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/python-essentials.html</guid>
      <description>&lt;p&gt;Python for AI/ML engineers. Virtual environments (venv, conda), pip &amp;amp; dependency management, key libraries (NumPy, Pandas), type hints, async basics, Jupyter notebooks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers</title>
      <link>https://ai.arkr.ca/transformers.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/transformers.html</guid>
      <description>&lt;p&gt;The Attention Mechanism, Self-Attention, and the Encoder-Decoder architecture.&lt;/p&gt;&#xA;&lt;p&gt;The Attention Mechanism, Self-Attention, Encoders/Decoders.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Git &amp; Version Control</title>
      <link>https://ai.arkr.ca/git-version-control.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/git-version-control.html</guid>
      <description>&lt;p&gt;Commits, branches, merges, pull requests. &lt;code&gt;.gitignore&lt;/code&gt; for Python/ML projects. Branching strategies (feature branches, trunk-based). Reviewing diffs, rolling back changes. Why AI shouldn&amp;rsquo;t auto-commit.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How LLMs Work</title>
      <link>https://ai.arkr.ca/how-llms-work.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/how-llms-work.html</guid>
      <description>&lt;p&gt;Predict-next-token logic, probability distributions, and the massive scale of pre-training.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG Systems</title>
      <link>https://ai.arkr.ca/rag-systems.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/rag-systems.html</guid>
      <description>&lt;p&gt;Retrieval-Augmented Generation: the &amp;ldquo;open book&amp;rdquo; approach. &lt;strong&gt;Architecture&lt;/strong&gt;: grounding AI in external data to reduce hallucinations. &lt;strong&gt;Pipeline&lt;/strong&gt;: document ingestion, chunking strategies, embedding, retrieval (similarity search), generation (prompt augmentation). Evaluating RAG quality.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Statistics for ML</title>
      <link>https://ai.arkr.ca/statistics-for-ml.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/statistics-for-ml.html</guid>
      <description>&lt;p&gt;Probability, Bayes&amp;rsquo; Theorem, Standard Deviation, and the Normal Distribution.&lt;/p&gt;&#xA;&lt;p&gt;Probability, Bayes&amp;rsquo; Theorem, Standard Deviation, Distributions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Workflow Patterns</title>
      <link>https://ai.arkr.ca/workflow-patterns.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/workflow-patterns.html</guid>
      <description>&lt;p&gt;Explore → Plan → Code → Commit workflow. Project structure and file organization for AI context. Permission modes for different tasks. Using &lt;code&gt;/clear&lt;/code&gt; between unrelated tasks. Parallel subagents for frontend/backend. Breaking large features into subtasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Code Review &amp; QA</title>
      <link>https://ai.arkr.ca/code-review-qa.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/code-review-qa.html</guid>
      <description>&lt;p&gt;Treating AI output like a teammate&amp;rsquo;s PR. Inspecting diffs, running tests, verifying logic. Unit tests, integration tests, CI/CD. Using AI to write tests. Multiple agents for write/review separation. Never blindly accepting changes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data &amp; Feature Engineering</title>
      <link>https://ai.arkr.ca/data-feature-engineering.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/data-feature-engineering.html</guid>
      <description>&lt;p&gt;Data collection and quality. Cleaning and preprocessing. Normalization and standardization. One-hot encoding and embeddings. Converting raw data into numerical vectors. Train/validation/test splits. Data augmentation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Environment &amp; Secrets</title>
      <link>https://ai.arkr.ca/environment-secrets.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/environment-secrets.html</guid>
      <description>&lt;p&gt;&lt;code&gt;.env&lt;/code&gt; files for configuration. &lt;code&gt;.env.example&lt;/code&gt; with placeholders. Never hardcode API keys or secrets. Never share secrets in prompts. Local vs production parity. Secret managers (GCP Secret Manager, AWS Secrets Manager).&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Parameters &amp; Control</title>
      <link>https://ai.arkr.ca/llm-parameters.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/llm-parameters.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;Sampling parameters&lt;/strong&gt;: Temperature, Top-K, Top-P (Nucleus) sampling for tuning creativity. &lt;strong&gt;Output control&lt;/strong&gt;: Max tokens, stop sequences, repetition penalties (frequency/presence). Balancing determinism vs. creativity. JSON mode and structured outputs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG Orchestration</title>
      <link>https://ai.arkr.ca/rag-orchestration.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/rag-orchestration.html</guid>
      <description>&lt;p&gt;Frameworks for building RAG pipelines: &lt;strong&gt;LangChain&lt;/strong&gt;, &lt;strong&gt;LlamaIndex&lt;/strong&gt;, &lt;strong&gt;Haystack&lt;/strong&gt;. Chains and runnables. Document loaders and splitters. Retriever abstractions. Advanced patterns: hybrid search, reranking, query transformation. When to use a framework vs. building from scratch.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Agents</title>
      <link>https://ai.arkr.ca/ai-agents.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/ai-agents.html</guid>
      <description>&lt;p&gt;Defining autonomy: models that use tools, reason through tasks, and pursue goals. &lt;strong&gt;Reasoning patterns&lt;/strong&gt;: ReAct (Reason + Act), Chain of Thought, step-back prompting, reflection. Agent loops: observe, think, act. Planning and task decomposition. Tool use and function calling.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Common Pitfalls</title>
      <link>https://ai.arkr.ca/common-pitfalls.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/common-pitfalls.html</guid>
      <description>&lt;p&gt;Over-reliance on AI without review. Prompt drift (AI changing things you didn&amp;rsquo;t ask for). Dependency bloat. Skipping tests. Accepting fixes that mask root causes. Context pollution from stale conversations. Security risks from unreviewed code.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Docker &amp; Containers</title>
      <link>https://ai.arkr.ca/docker-containers.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/docker-containers.html</guid>
      <description>&lt;p&gt;Containerization for reproducible ML environments. Dockerfiles, images, containers. docker-compose for multi-service setups. GPU support with NVIDIA Docker. Container registries. Why containers matter for ML deployment.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Landscape</title>
      <link>https://ai.arkr.ca/model-landscape.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/model-landscape.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;Proprietary models&lt;/strong&gt;: OpenAI (GPT series), Anthropic (Claude), Google (Gemini), xAI (Grok). &lt;strong&gt;Open source models&lt;/strong&gt;: Meta (Llama), Mistral, Qwen. The Hugging Face ecosystem. Comparing capabilities, costs, and use cases. When to use open vs. closed models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Supervised Learning</title>
      <link>https://ai.arkr.ca/supervised-learning.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/supervised-learning.html</guid>
      <description>&lt;p&gt;Regression (Linear/Logistic) and Classification; the process of training on labeled data.&lt;/p&gt;&#xA;&lt;p&gt;Regression (Linear/Logistic), Classification, Labeling data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building Agents</title>
      <link>https://ai.arkr.ca/building-agents.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/building-agents.html</guid>
      <description>&lt;p&gt;Implementation approaches: manual loops vs. frameworks. &lt;strong&gt;Tools&lt;/strong&gt;: OpenAI Functions/Tools API, Anthropic tool use. &lt;strong&gt;Frameworks&lt;/strong&gt;: LangGraph, Google ADK, CrewAI, AutoGen. Defining tools and schemas. Error handling and retries. Memory and state management.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Prompt Engineering</title>
      <link>https://ai.arkr.ca/prompt-engineering.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/prompt-engineering.html</guid>
      <description>&lt;p&gt;Zero-shot vs. few-shot prompting. Chain of Thought (CoT) reasoning. Self-consistency and ensemble methods. Tree of Thoughts (ToT). Role prompting and persona setting. Structured prompts with examples. System vs. user prompts. Iterative refinement. Common patterns and anti-patterns.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SQL &amp; Databases</title>
      <link>https://ai.arkr.ca/sql-databases.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/sql-databases.html</guid>
      <description>&lt;p&gt;Relational databases (Postgres, MySQL). SQL fundamentals: SELECT, INSERT, UPDATE, DELETE, JOINs. Indexing and query optimization. BigQuery for analytics at scale. Database connections in Python.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unsupervised Learning</title>
      <link>https://ai.arkr.ca/unsupervised-learning.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/unsupervised-learning.html</guid>
      <description>&lt;p&gt;Finding patterns in unlabeled data; Clustering (K-Means) and Dimensionality Reduction (PCA).&lt;/p&gt;&#xA;&lt;p&gt;Clustering (K-Means), Dimensionality reduction.&lt;/p&gt;</description>
    </item>
    <item>
      <title>APIs &amp; HTTP</title>
      <link>https://ai.arkr.ca/apis-http.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/apis-http.html</guid>
      <description>&lt;p&gt;HTTP fundamentals: verbs (GET, POST, PUT, DELETE), status codes, headers. REST API design. Building APIs with FastAPI. Authentication (API keys, OAuth, JWT). Rate limiting. OpenAPI/Swagger documentation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Context Engineering</title>
      <link>https://ai.arkr.ca/context-engineering.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/context-engineering.html</guid>
      <description>&lt;p&gt;Context window management and token budgeting. Chunking strategies for long documents. Memory architectures for conversations. &lt;strong&gt;Optimization&lt;/strong&gt;: KV cache mechanics, prompt caching, context compression. Balancing context length with latency and cost.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multi-Agent Systems</title>
      <link>https://ai.arkr.ca/multi-agent-systems.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/multi-agent-systems.html</guid>
      <description>&lt;p&gt;Orchestrating multiple agents. &lt;strong&gt;Patterns&lt;/strong&gt;: supervisor/worker, hierarchical, collaborative. Agent communication and handoffs. LangGraph for stateful multi-agent workflows. Parallel vs. sequential execution. Debugging and observability. Production considerations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural Networks</title>
      <link>https://ai.arkr.ca/neural-networks.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/neural-networks.html</guid>
      <description>&lt;p&gt;Perceptrons and multi-layer networks. Weights, biases, and activation functions (ReLU, Sigmoid, Softmax). &lt;strong&gt;Learning process&lt;/strong&gt;: loss functions, gradient descent, backpropagation. Epochs and batch sizes. Overfitting and regularization. CNNs for vision, RNNs for sequences.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Formats</title>
      <link>https://ai.arkr.ca/data-formats.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/data-formats.html</guid>
      <description>&lt;p&gt;JSON for APIs and config. YAML for configuration files. CSV for tabular data. Parquet for efficient ML data storage. Serialization/deserialization in Python. Protocol Buffers for gRPC.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fine-tuning &amp; Deployment</title>
      <link>https://ai.arkr.ca/finetuning-deployment.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/finetuning-deployment.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;When to fine-tune&lt;/strong&gt;: vs. prompting, vs. RAG. Fine-tuning techniques: LoRA, QLoRA, full fine-tuning. &lt;strong&gt;Deployment options&lt;/strong&gt;: Cloud APIs (OpenAI, Anthropic). Self-hosting with Ollama, vLLM, TGI. Azure AI, AWS SageMaker, GCP Vertex AI. Cost and latency considerations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Context Protocol</title>
      <link>https://ai.arkr.ca/model-context-protocol.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/model-context-protocol.html</guid>
      <description>&lt;p&gt;MCP: a standard for connecting LLMs to data and tools. &lt;strong&gt;Architecture&lt;/strong&gt;: hosts, clients, servers, transport layer. Building MCP servers for custom data sources. Integrating with Cursor, Claude Desktop. Resources, tools, and prompts. Security considerations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training &amp; Inference</title>
      <link>https://ai.arkr.ca/training-inference.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/training-inference.html</guid>
      <description>&lt;p&gt;The computational cost of training vs. inference. GPU/TPU requirements. Pre-training vs. fine-tuning. Model optimization: quantization, distillation, pruning. Deployment considerations: latency, throughput, cost. Batch vs. real-time inference.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Structures &amp; Complexity</title>
      <link>https://ai.arkr.ca/data-structures.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/data-structures.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;Data Structures&lt;/strong&gt;: Arrays and lists (contiguous memory, O(1) access). Hash tables (key-value mapping, O(1) lookup). Trees (hierarchical data, traversal). Graphs (nodes and edges, adjacency representations).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Complexity Analysis&lt;/strong&gt;: Big-O notation. Time complexity: O(1), O(log n), O(n), O(n²). Space complexity. Why complexity matters for ML inference at scale. Choosing the right structure for AI/ML pipelines.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multimodal AI</title>
      <link>https://ai.arkr.ca/multimodal-ai.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/multimodal-ai.html</guid>
      <description>&lt;p&gt;Beyond text: handling images, audio, and video. &lt;strong&gt;Vision&lt;/strong&gt;: image understanding (GPT-4V, Claude Vision), image generation (DALL-E, Midjourney, Stable Diffusion). &lt;strong&gt;Audio&lt;/strong&gt;: speech-to-text (Whisper), text-to-speech. &lt;strong&gt;Video&lt;/strong&gt;: understanding and generation. Building multimodal applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Safety &amp; Security</title>
      <link>https://ai.arkr.ca/ai-safety-security.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/ai-safety-security.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;Security risks&lt;/strong&gt;: prompt injection, jailbreaking, data extraction. &lt;strong&gt;Reliability&lt;/strong&gt;: hallucinations, bias, inconsistency. &lt;strong&gt;Mitigations&lt;/strong&gt;: input validation, output filtering, moderation APIs (OpenAI). Guardrails and content policies. End-user IDs for abuse prevention. Red-teaming and adversarial testing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>System Design Basics</title>
      <link>https://ai.arkr.ca/system-design-basics.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/system-design-basics.html</guid>
      <description>&lt;p&gt;Scaling: vertical vs horizontal. Caching strategies: write-through, write-back, LRU eviction. Message queues: producers, consumers, async processing. Load balancing. Stateless vs stateful services. Designing for ML inference workloads.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Evaluation</title>
      <link>https://ai.arkr.ca/llm-evaluation.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/llm-evaluation.html</guid>
      <description>&lt;p&gt;Measuring LLM quality. &lt;strong&gt;Benchmarks&lt;/strong&gt;: MMLU, HumanEval, HELM. &lt;strong&gt;RAG metrics&lt;/strong&gt;: precision, recall, faithfulness. Custom evaluation frameworks. Human evaluation and annotation. A/B testing in production. LLM-as-a-judge patterns. Continuous monitoring and regression detection.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MLOps &amp; Cloud Platforms</title>
      <link>https://ai.arkr.ca/mlops-cloud-platforms.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ai.arkr.ca/mlops-cloud-platforms.html</guid>
      <description>&lt;p&gt;&lt;strong&gt;Experiment tracking&lt;/strong&gt;: MLflow, Weights &amp;amp; Biases. Model registries and versioning. &lt;strong&gt;Pipeline orchestration&lt;/strong&gt;: Airflow, Prefect. CI/CD for ML. &lt;strong&gt;Cloud platforms&lt;/strong&gt;: GCP Vertex AI (training, serving, ADK), Azure ML, AWS SageMaker. Comparing costs, features, and when to use each.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
